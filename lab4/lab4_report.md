# Лабораторная работа №4 — Разработка инфраструктуры MVP AI приложения

University: [ITMO University](https://itmo.ru/ru/)  
Faculty: FTMI  
Course: [introduction-in-web-tech](https://itmo-ict-faculty.github.io/introduction-in-web-tech)  
Year: 2025/2026  
Group: U4225  
Author: Гунин Никита Алексеевич  
Lab: Lab4  
Date of create: 02.12.2025  
Date of finished: 02.12.2025

---

## Цель работы

Разработать инфраструктурную схему и экономическую модель для MVP AI‑приложения — **ИИ‑менеджера поддержки для малого бизнеса**, определить ресурсы для трёх стадий развития:  
1) стартовая (MVP),  
2) тестирование партнёрами,  
3) продовое решение.

---

## Исходные данные: AI‑менеджер поддержки

Приложение предоставляет малому бизнесу автоматизированный канал поддержки на основе ИИ:

- обработка обращений клиентов (чат/почта),
- генерация ответов,
- анализ тональности,
- подключение к CRM,
- история чатов.

Рабочая нагрузка по стадиям:

| Стадия | Пользователи | Запросов в сутки | Требования |
|--------|--------------|------------------|------------|
| MVP | 30–50 компаний | 2–5k | минимальные затраты, быстрый запуск |
| Тестирование | 100–300 компаний | 10–30k | стабильность, мониторинг |
| Прод | 2000+ компаний | 150–300k | стабильный API, автоскейлинг, безопасное хранение данных |

---

## Инфраструктурная схема (описание для draw.io)

### **1. MVP (минимальная стоимость, простота запуска)**

- **Frontend**:  
  - Static hosting → *Cloud Storage + Cloud CDN (optional)*  

- **Backend API**:  
  - *Cloud Run* (одна ревизия, 0.5 vCPU, 512MB)  
  - Автоскейлинг: min=0, max=3

- **LLM модель**:  
  - Внешний API: *OpenAI / Gemini / DeepSeek API*  
  - Затраты только на вызовы модели

- **База данных**:  
  - *Firestore (Native Mode)*  
  - Дешево, serverless, подходит для MVP

- **Аутентификация**:  
  - Firebase Auth

- **Логи/мониторинг**:  
  - Cloud Logging + Cloud Monitoring (free tier)

---

### **2. Тестирование партнерами (повышенные требования)**

Добавляется устойчивость, безопасность, бóльшая скорость:

- Cloud Run увеличено до:  
  - 1 vCPU / 1GB RAM / max=10 инстансов

- Используется **Vertex AI API** как fallback к внешнему API

- Firestore → сохраняется, но вводится:  
  - *Cloud Storage 10–20GB* для логов и вложений

- Вводится **Pub/Sub** для очередей длинных задач

- Login rate limiting через **API Gateway**

---

### **3. Прод решение (масштабируемость и надежность)**

- Backend переходит на **GKE Autopilot**  
  - микросервисы: gateway, ingestion, llm-proxy, monitoring-agent

- Модель:  
  - Vertex AI LLM (fine‑tuning небольшого размера)  
  - Кэширование ответов Redis (MemoryStore)

- Данные:  
  - PostgreSQL (Cloud SQL) — устойчивое хранение клиентов  
  - Firestore — быстрые записи чатов  
  - Storage — вложения и ресурсы

- Сетевая безопасность:  
  - VPC  
  - Serverless VPC connector  
  - IAM‑политики

---

## Экономическая модель

### **MVP стоимость**

| Ресурс | Цена | Описание |
|--------|------|----------|
| Cloud Run | ~5–12$/мес | минимальная нагрузка |
| Firestore | ~1–3$/мес | документы и история чатов |
| Storage | ~0.2$/мес | статика |
| External API (LLM) | ~20–60$/мес | на основе 2–5k запросов |
| Итого | **~30–80$/мес** |

---

### **Тестирование партнерами**

| Ресурс | Цена |
|--------|------|
| Cloud Run | 30–60$/мес |
| Firestore | 8–15$/мес |
| Storage | 1–4$/мес |
| Pub/Sub | 1–2$/мес |
| LLM | 100–300$/мес |
| Итого | **150–380$/мес** |

---

### **Прод**

| Ресурс | Цена |
|--------|------|
| GKE Autopilot | 200–400$/мес |
| Cloud SQL | 70–150$/мес |
| Firestore | 40–80$/мес |
| Storage | 20–40$/мес |
| LLM (Vertex AI) | 500–1500$/мес |
| Итого | **~900–2000$/мес** |

---

## Диаграмма
![MVP Schema.png](.lab4/MVP Schema.png)

## Обоснование выбора ресурсов

- **Cloud Run** — идеален для MVP: быстро, дешево, без серверов.  
- **Vertex AI / external API** — не требует обслуживания, подходит для экспериментов.  
- **Firestore** — горизонтальное масштабирование и простая работа с JSON‑объектами.  
- **GKE Autopilot** в проде — лучшая балансировка нагрузки и адаптация под рост.  
- **Cloud SQL** — критично для структурированных данных: тарифы, компании, роли.  
- **Pub/Sub** — обеспечивает устойчивость при всплесках нагрузки.  
- **Storage** — дешёвое хранение файлов.

---

## Выводы

В ходе лабораторной я разработал:

- архитектурную схему инфраструктуры в трёх состояниях,
- экономическую модель расходов на разных этапах,
- обоснование выбора технологий и сервисов Google Cloud.

AI‑менеджер поддержки может быть запущен дешево как MVP и плавно масштабирован до прод‑уровня без изменения логики приложения — лишь с заменой инфраструктурных слоев.

---
